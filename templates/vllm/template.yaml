apiVersion: leaderworkerset.x-k8s.io/v1
kind: LeaderWorkerSet
metadata:
  name: $deployment_name
  labels:
    # must have this label
    kalavai.lws.name: $deployment_name
spec:
  replicas: $replicas
  leaderWorkerTemplate:
    size: $num_workers
    restartPolicy: RecreateGroupOnPodRestart
    leaderTemplate:
      metadata:
        labels:
          role: leader
          kalavai.lws.name: $deployment_name
      spec:
        runtimeClassName: nvidia
        containers:
        - name: vllm-leader
          image: bundenth/ray-vllm:v1.1.2
          env:
          - name: HUGGING_FACE_HUB_TOKEN
            value: $hf_token
          command:
            - sh
            - -c
            - "/home/ray/workspace/ray_init.sh leader --ray_cluster_size=$num_workers --ray_object_store_memory=$shmem_size;
                sleep 30;
                ray status;
                /home/ray/workspace/run_model.sh \
                  --model_id=$model_id \
                  --extra='$extra' \
                  --tensor_parallel_size=$tensor_parallel_size \
                  --pipeline_parallel_size=$pipeline_parallel_size;
                sleep 30"
          resources:
            requests:
              cpu: "$cpus"
              memory: $memory
              nvidia.com/gpu: "$gpus"
            limits:
              cpu: "$cpus"
              memory: $memory
              nvidia.com/gpu: "$gpus"
          ports:
          # if use 8080 as exposed port (if required)
          - containerPort: 8080
          readinessProbe:
            tcpSocket:
              port: 8080
            initialDelaySeconds: 90
            periodSeconds: 30
          volumeMounts:
            - mountPath: /dev/shm
              name: dshm
        volumes:
        - name: dshm
          emptyDir:
            medium: Memory
            sizeLimit: $shmem_size
    workerTemplate:
      spec:
        runtimeClassName: nvidia
        containers:
        - name: vllm-worker
          image: bundenth/ray-vllm:v1.1.2
          env:
            - name: HUGGING_FACE_HUB_TOKEN
              value: $hf_token
          command:
            - sh
            - -c
            - "RAY_BACKEND_LOG_LEVEL=error /home/ray/workspace/ray_init.sh worker --ray_address=$$LWS_LEADER_ADDRESS --ray_object_store_memory=$shmem_size --ray_block=1"
          resources:
            requests:
              cpu: "$cpus"
              memory: $memory
              nvidia.com/gpu: "$gpus"
            limits:
              cpu: "$cpus"
              memory: $memory
              nvidia.com/gpu: "$gpus"
          volumeMounts:
            - mountPath: /dev/shm
              name: dshm   
        volumes:
        - name: dshm
          emptyDir:
            medium: Memory
            sizeLimit: $shmem_size